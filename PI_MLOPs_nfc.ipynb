{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROYECTO INDIVIDUAL DE MLOPs (Machine Learning Operations)\n",
    "\n",
    "NESTOR CARDONA\n",
    "\n",
    "ETL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ETL 1RA PARTE\n",
    "AQUI SE EMPIEZA LA EXTRACCION\n",
    "\n",
    "PASO 1: SE CARGAN LOS 3 ARCHIVOS JSON Y LOS CONVERTIMOS A DATAFRAMES DE PANDAS\n",
    "steam_games.json, users_items.json y user_reviews.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import jsonlines\n",
    "import ast\n",
    "import gzip\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "import random\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "AQUI SE CARGA: steam_games.json.gz y se descomprme y luego \n",
    "Se pasa a dataset de pandas y se pasa a archivo CSV para luego revisar la data\n",
    "'''\n",
    "\n",
    "def descomprime(ruta):\n",
    "    with gzip.open(ruta,'r') as g:\n",
    "        for i in g:\n",
    "            yield json.loads(i)\n",
    "    return\n",
    "\n",
    "# Cargar el archivo JSON línea por línea\n",
    "archivo_json = \"steam_games.json.gz\"  # Ruta al archivo JSON\n",
    "rows=[]\n",
    "\n",
    "for line in descomprime(archivo_json):\n",
    "     row = pd.json_normalize(line)\n",
    "     rows.append(row)\n",
    "\n",
    "games = pd.concat(rows, ignore_index=True)\n",
    "\n",
    "\n",
    "# Pasar DataFrame games a steam_games_orig.csv\n",
    "archivo_csv= 'steam_games_orig.csv'\n",
    "games.to_csv(archivo_csv, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "AQUI SE CARGA: user_reviews.json (descomprimido por winzip)\n",
    "Se pasa a dataset de pandas, luego se descomprime el campo \"reviews\"\n",
    "que es un campo JSON y luego se pasa archivo desanidado a CSV para luego revisar la data\n",
    "'''\n",
    "\n",
    "# Cargar el archivo JSON línea por línea\n",
    "archivo_json = \"user_reviews.json\"\n",
    "rows = []\n",
    "\n",
    "with open(archivo_json, \"r\",encoding = 'utf-8') as json_file:\n",
    "    for line in json_file.readlines():\n",
    "        rows.append(ast.literal_eval(line))\n",
    "\n",
    "# Convertir los objetos JSON a un DataFrame de pandas\n",
    "df_users_reviews = pd.DataFrame(rows)\n",
    "\n",
    "# Crear un bucle para descomprimir el campo 'reviews'\n",
    "for i, row in df_users_reviews.iterrows():\n",
    "    review_data = row['reviews']\n",
    "    new_columns = pd.json_normalize(review_data)\n",
    "    for col in new_columns.columns:\n",
    "        df_users_reviews.at[i, col] = new_columns.at[0, col]\n",
    "\n",
    "# Eliminar la columna original 'reviews' si es necesario\n",
    "df_users_reviews.drop('reviews', axis=1, inplace=True)\n",
    "\n",
    "df_users_reviews.rename(columns={'item_id': 'id'}, inplace=True)\n",
    "\n",
    "# Pasar DataFrame users_reviews a users_reviews_orig.csv\n",
    "archivo_csv = 'users_reviews_orig.csv'\n",
    "df_users_reviews.to_csv(archivo_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "AQUI SE CARGA: users_items.json (descomprimido por winzip)\n",
    "Se pasa a dataset de pandas, luego se descomprime el campo \"items\"\n",
    "que es un campo JSON y luego se pasa archivo desanidado a CSV para luego revisar la data\n",
    "'''\n",
    "\n",
    "# Cargar el archivo JSON línea por línea\n",
    "archivo_json = \"users_items.json\"\n",
    "rows = []\n",
    "\n",
    "with open(archivo_json, \"r\",encoding = 'utf-8') as json_file:\n",
    "    for line in json_file.readlines():\n",
    "        rows.append(ast.literal_eval(line))\n",
    "# Convertir los objetos JSON a un DataFrame de pandas\n",
    "df_user_items = pd.DataFrame(rows)\n",
    "\n",
    "# Crear un bucle para descomprimir el campo 'reviews'\n",
    "for i, row in df_user_items.iterrows():\n",
    "    review_data = row['items']\n",
    "    new_columns = pd.json_normalize(review_data)\n",
    "    for col in new_columns.columns:\n",
    "        df_user_items.at[i, col] = new_columns.at[0, col]\n",
    "\n",
    "# Eliminar la columna original 'reviews' si es necesario\n",
    "df_user_items.drop('items', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Pasar DataFrame users_reviews a users_reviews_orig.csv\n",
    "archivo_csv = 'users_items_orig.csv'\n",
    "df_user_items.to_csv(archivo_csv, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ETL 2DA PARTE\n",
    "AQUI SE EMPIEZA A TRANSFORMAR LA INFORMACION EXTRAIDA\n",
    "\n",
    "PASO 2: SE DEPURAN LOS 3 ARCHIVOS CSV EXTRAIDOS EN LA 1RA PARTE\n",
    "steam_games_orig.csv, users_items_orig.csv y user_reviews_orig.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargar el archivo users_reviews_orig.csv\n",
    "\n",
    "BORRAMOS LOS NaN DEL CAMPO 'item_id' DE df_users_reviews (users_items_orig.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEPURACION DE DATOS EN user_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de NaN en la columna 'user_id': 0\n",
      "Número de NaN en cada columna del DataFrame:\n",
      "user_id            0\n",
      "user_url           0\n",
      "funny          21567\n",
      "posted             0\n",
      "last_edited    23744\n",
      "item_id            0\n",
      "helpful            0\n",
      "recommend          0\n",
      "review            12\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cargar el archivo CSV\n",
    "df_users_reviews = pd.read_csv('users_reviews_orig.csv')\n",
    "\n",
    "# Eliminar filas con valores NaN en el campo 'item_id'\n",
    "df_users_reviews = df_users_reviews.dropna(subset=['item_id'])\n",
    "\n",
    "\n",
    "# Contar cuántos valores NaN hay en una columna específica\n",
    "nan_count_column = df_users_reviews['user_id'].isna().sum()\n",
    "print(\"Número de NaN en la columna 'user_id':\", nan_count_column)\n",
    "\n",
    "# Contar cuántos valores NaN hay en todas las columnas del DataFrame\n",
    "nan_count_dataframe = df_users_reviews.isna().sum()\n",
    "print(\"Número de NaN en cada columna del DataFrame:\")\n",
    "print(nan_count_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BORRAMOS LOS NaN DEL CAMPO 'item_id' DE df_user_items (users_items_orig.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEPURACION DE DATOS EN user_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de NaN en la columna 'steam_id': 0\n",
      "Número de NaN en cada columna del DataFrame:\n",
      "user_id             0\n",
      "items_count         0\n",
      "steam_id            0\n",
      "user_url            0\n",
      "item_id             0\n",
      "item_name           0\n",
      "playtime_forever    0\n",
      "playtime_2weeks     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cargar el archivo CSV\n",
    "df_user_items = pd.read_csv('users_items_orig.csv')\n",
    "\n",
    "# Eliminar filas con valores NaN en el campo 'item_id'\n",
    "df_user_items = df_user_items.dropna(subset=['item_id'])\n",
    "\n",
    "# Contar cuántos valores NaN hay en una columna específica\n",
    "nan_count_column = df_user_items['steam_id'].isna().sum()\n",
    "print(\"Número de NaN en la columna 'steam_id':\", nan_count_column)\n",
    "\n",
    "# Contar cuántos valores NaN hay en todas las columnas del DataFrame\n",
    "nan_count_dataframe = df_user_items.isna().sum()\n",
    "\n",
    "print(\"Número de NaN en cada columna del DataFrame:\")\n",
    "print(nan_count_dataframe)\n",
    "\n",
    "\n",
    "# Pasar DataFrame users_reviews a users_reviews_orig.csv\n",
    "archivo_csv = 'users_items_sin_NaN.csv'\n",
    "df_user_items.to_csv(archivo_csv, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRANSFORMACIONES EN steam_games \n",
    "\n",
    "CREAR CAMPO 'year' SACADO DEL CAMPO 'release_date'\n",
    "CREAR CAMPOS CON LOS GENEROS MAS USADOS (99.3%), SACADOS DEL CAMPO 'tags' \n",
    "ELIMINAR COLUMNAS NO NECESARIAS PARA LOS ENDPOINTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el archivo CSV\n",
    "df_steam_games = pd.read_csv('steam_games_orig.csv')\n",
    "\n",
    "#Agregar campo 'year' del sacado del campo 'release_date'\n",
    "df_steam_games['year'] = pd.to_datetime(df_steam_games['release_date'], errors='coerce').apply(lambda x: str(x).split('-')[0] if pd.notnull(x) else None)\n",
    "\n",
    "\n",
    "# Eliminar filas con valores NaN en el campo 'id'\n",
    "df_steam_games = df_steam_games.dropna(subset=['id'])\n",
    "\n",
    "# Eliminar filas con valores NaN en el campo 'tags' que se va a usar para \n",
    "# GENERO ya que el campo 'genre' tiene muchos mas NaN y la info en ambas columnas es igual\n",
    "df_steam_games = df_steam_games.dropna(subset=['tags'])\n",
    "\n",
    "\n",
    "# Contar cuántos valores NaN hay en una columna específica\n",
    "nan_count_column = df_steam_games['id'].isna().sum()\n",
    "print(\"Número de NaN en la columna 'id':\", nan_count_column)\n",
    "\n",
    "# Contar cuántos valores NaN hay en todas las columnas del DataFrame\n",
    "nan_count_dataframe = df_steam_games.isna().sum()\n",
    "print(\"Número de NaN en cada columna del DataFrame:\")\n",
    "print(nan_count_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El DataFrame tiene 31971 filas.\n"
     ]
    }
   ],
   "source": [
    "# Obtener el número de filas\n",
    "num_filas = df_steam_games.shape[0]\n",
    "\n",
    "# Imprimir el número de filas\n",
    "print(f\"El DataFrame tiene {num_filas} filas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SE CRE EL DF df_games_tags CON LOS GENEROS DE LA COLUMNA 'tags' \n",
    "# LUEGO ORDENO DESCENCENTEMENTE LOS MAS IMPORTANTES Y CON LOS MAS RELEVANTES\n",
    "# CREO EL DF tags_pareto PARA CONCATENARLO AL FINAL AL DF  df_steam_games\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea un DF con los generos de la columna 'tags' \n",
    "\n",
    "# Verificar si el valor es una lista antes de usar ast.literal_eval\n",
    "df_steam_games['tags'] = df_steam_games['tags'].apply(lambda x: x if isinstance(x, list) else ast.literal_eval(x))\n",
    "#df_steam_games['tags'] = df_steam_games['tags'].apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "# Luego, continúa con el procesamiento\n",
    "games_tags = pd.DataFrame(df_steam_games['tags'].tolist())\n",
    "games_tags_obj = games_tags.stack()\n",
    "df_games_tags = pd.get_dummies(games_tags_obj)\n",
    "df_games_tags=df_games_tags.groupby(level=[0], axis=0).sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ordeno en orden descendente los 15 GENEROS mas importantes, con mas seleccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Indie               0.551124\n",
       "Action              0.406744\n",
       "Adventure           0.307466\n",
       "Casual              0.304620\n",
       "Simulation          0.241782\n",
       "Strategy            0.236652\n",
       "RPG                 0.185137\n",
       "Singleplayer        0.135904\n",
       "Free to Play        0.075256\n",
       "Multiplayer         0.074536\n",
       "Great Soundtrack    0.069907\n",
       "Puzzle              0.066029\n",
       "Early Access        0.060899\n",
       "2D                  0.060836\n",
       "Atmospheric         0.060492\n",
       "dtype: float64"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ordeno en orden descendente los 15 GENEROS mas importantes, con mas seleccion\n",
    "df_games_tags.sum().sort_values(ascending=False).head(15)/len(df_games_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecciono los GENEROS mas importantes del DF para concatenarlos \n",
    "\n",
    "tags_pareto=  df_games_tags[['Indie','Action','Adventure','Casual','Simulation','Strategy','RPG','Singleplayer','Free to Play','Multiplayer']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El DataFrame tiene 31971 filas.\n"
     ]
    }
   ],
   "source": [
    "# Obtener el número de filas\n",
    "num_filas = tags_pareto.shape[0]\n",
    "\n",
    "# Imprimir el número de filas\n",
    "print(f\"El DataFrame tiene {num_filas} filas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SE CONCATENA AL FINAL DEL DF df_games_final EL DF tags_pareto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restablece el índice de df_steam_games antes de la concatenación\n",
    "df_steam_games.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Concatena los DataFrames sin duplicar filas\n",
    "df_games_final = pd.concat([df_steam_games, tags_pareto], axis=1)\n",
    "df_games_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El DataFrame tiene 31971 filas.\n"
     ]
    }
   ],
   "source": [
    "# Obtener el número de filas\n",
    "num_filas = df_games_final.shape[0]\n",
    "\n",
    "# Imprimir el número de filas\n",
    "print(f\"El DataFrame tiene {num_filas} filas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BORRAMOS LAS COLUMNAS NO NECESARIAS PARA LOS ENDPOINTS PARA QUE SEAN RAPIDAS LAS QUERYS\n",
    " 'publisher','genres','title','url','release_date','tags','reviews_url','discount_price','specs','price','early_access','metascore','developer','items','items_count'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BORRAMOS LAS COLUMNAS NO NECESARIAS PARA LOS ENDPOINTS PARA QUE SEAN RAPIDAS LAS QUERYS\n",
    "df_games_final = df_games_final.drop(['publisher','genres','title','url','release_date','tags','reviews_url','discount_price','specs','price','early_access','metascore','developer','items','items_count'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31971 entries, 0 to 31970\n",
      "Data columns (total 15 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   app_name      31970 non-null  object \n",
      " 1   id            31971 non-null  float64\n",
      " 2   user_id       0 non-null      object \n",
      " 3   steam_id      0 non-null      float64\n",
      " 4   year          29621 non-null  object \n",
      " 5   Indie         31971 non-null  int64  \n",
      " 6   Action        31971 non-null  int64  \n",
      " 7   Adventure     31971 non-null  int64  \n",
      " 8   Casual        31971 non-null  int64  \n",
      " 9   Simulation    31971 non-null  int64  \n",
      " 10  Strategy      31971 non-null  int64  \n",
      " 11  RPG           31971 non-null  int64  \n",
      " 12  Singleplayer  31971 non-null  int64  \n",
      " 13  Free to Play  31971 non-null  int64  \n",
      " 14  Multiplayer   31971 non-null  int64  \n",
      "dtypes: float64(2), int64(10), object(3)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df_games_final.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SE CREA EL ARCHIVO CSV FINAL DE GAMES games_final.csv PARA ENDPOINTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pasar DataFrame df_games_final a games_final.csv listo para los ENDPOINTS\n",
    "archivo_csv = 'games_final.csv'\n",
    "df_games_final.to_csv(archivo_csv, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRANSFORMACIONES EN user_reviews \n",
    "\n",
    "CREAR CAMPO 'year' SACADO DEL CAMPO 'posted'\n",
    "CREAR CAMPO 'sentimiento' CON LA FUNCION analizar_sentimiento SACADO DEL CAMPO 'review'\n",
    "ELIMINAR COLUMNAS NO NECESARIAS PARA LOS ENDPOINTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_reviews_final = pd.read_csv('users_reviews_orig.csv')\n",
    "df_reviews_final.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SE CREA CAMPO 'sentimiento' CON ANALISIS DE SENTIMIENTO AL CAMPO 'review'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  review sentimiento\n",
      "0      Simple yet with great replayability. In my opi...    Positivo\n",
      "1      I know what you think when you see this title ...    Positivo\n",
      "2      A suitably punishing roguelike platformer.  Wi...    Positivo\n",
      "3      This game... is so fun. The fight sequences ha...    Positivo\n",
      "4                                                Git gud     Neutral\n",
      "...                                                  ...         ...\n",
      "25794  I cried in the end its so sadding ]'; I wish l...    Positivo\n",
      "25795  Gra naprawdę fajna.Ale jest kilka rzeczy do kt...     Neutral\n",
      "25796                                          Well Done     Neutral\n",
      "25797  this is a very fun and nice 80s themed shooter...    Positivo\n",
      "25798  had so much fun plaing this and collecting res...    Positivo\n",
      "\n",
      "[25799 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "def analizar_sentimiento(texto):\n",
    "    if isinstance(texto, str):  # Verificar si es una cadena de caracteres\n",
    "        analysis = TextBlob(texto)\n",
    "        # Clasificar el sentimiento como positivo, negativo o neutral\n",
    "        if analysis.sentiment.polarity > 0:\n",
    "            return 'Positivo'\n",
    "        elif analysis.sentiment.polarity < 0:\n",
    "            return 'Negativo'\n",
    "    return 'Neutral'\n",
    "\n",
    "# Aplicar el análisis de sentimiento al campo 'recommended' y crear un nuevo campo 'sentimiento'\n",
    "df_reviews_final['sentimiento'] = df_reviews_final['review'].apply(analizar_sentimiento)\n",
    "\n",
    "# Verificar el resultado\n",
    "print(df_reviews_final[['review', 'sentimiento']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pasar DataFrame df_games_final a games_final.csv listo \n",
    "archivo_csv = 'reviews_sentim.csv'\n",
    "df_reviews_final.to_csv(archivo_csv, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SE CREA CAMPO 'year' EXTRAIDO DEL CAMPO 'posted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para extraer el año de la cadena 'posted'\n",
    "def extract_year(posted_str):\n",
    "    if isinstance(posted_str, str):\n",
    "        match = re.search(r'\\d{4}', posted_str)\n",
    "        if match:\n",
    "            return match.group()\n",
    "    return None  # Opcionalmente, puedes asignar un valor predeterminado en lugar de None\n",
    "df_reviews_final = pd.read_csv('reviews_sentim.csv')\n",
    "\n",
    "# Aplicar la función extract_year y crear la columna 'year'\n",
    "df_reviews_final['year'] = df_reviews_final['posted'].apply(extract_year)\n",
    "\n",
    "# Mostrar el DataFrame resultante\n",
    "print(df_reviews_final)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BORRAMOS CAMPOS INNECESARIOS DE df_reviews_final PARA DAR PASO AL DEFINITIVO\n",
    "# QUE SE USARA PARA LOS ENDPOINTS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiamos el typo float del campo a object\n",
    "df_reviews_final['id'] = df_reviews_final['id'].astype(object)\n",
    "\n",
    "\n",
    "# BORRAMOS LAS COLUMNAS NO NECESARIAS PARA LOS ENDPOINTS PARA QUE SEAN RAPIDAS LAS QUERYS\n",
    "df_reviews_final = df_reviews_final.drop(['user_url','funny','posted','last_edited','helpful'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25799 entries, 0 to 25798\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   user_id      25799 non-null  object\n",
      " 1   id           25771 non-null  object\n",
      " 2   recommend    25771 non-null  object\n",
      " 3   review       25759 non-null  object\n",
      " 4   sentimiento  25799 non-null  object\n",
      " 5   year         21069 non-null  object\n",
      "dtypes: object(6)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_reviews_final.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renombrar campo\n",
    "#df_reviews_final.rename(columns={'item_id': 'id'}, inplace=True)\n",
    "\n",
    "# Cambiamos el typo float del campo a object\n",
    "df_reviews_final['id'] = df_reviews_final['id'].astype(object)\n",
    "\n",
    "# Pasar DataFrame df_reviews_final a reviews_final.csv listo para los ENDPOINTS\n",
    "archivo_csv = 'reviews_final.csv'\n",
    "df_reviews_final.to_csv(archivo_csv, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRANSFORMACIONES EN user_items \n",
    "\n",
    "RENOMBRAR CAMPO 'item_id' A 'id' PARA MEJORAR JOINS \n",
    "ELIMINAR COLUMNAS NO NECESARIAS PARA LOS ENDPOINTS\n",
    "CREAR ARCHIVO FINAL CSV 'items_final.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 88310 entries, 0 to 88309\n",
      "Data columns (total 8 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   user_id           88310 non-null  object \n",
      " 1   items_count       88310 non-null  int64  \n",
      " 2   steam_id          88310 non-null  int64  \n",
      " 3   user_url          88310 non-null  object \n",
      " 4   item_id           71504 non-null  float64\n",
      " 5   item_name         71504 non-null  object \n",
      " 6   playtime_forever  71504 non-null  float64\n",
      " 7   playtime_2weeks   71504 non-null  float64\n",
      "dtypes: float64(3), int64(2), object(3)\n",
      "memory usage: 5.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_items_final = pd.read_csv('users_items_orig.csv')\n",
    "df_items_final.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BORRAMOS LAS COLUMNAS NO NECESARIAS PARA LOS ENDPOINTS PARA QUE SEAN RAPIDAS LAS QUERYS\n",
    "df_items_final = df_items_final.drop(['items_count','user_url','playtime_2weeks','steam_id','item_name'], axis=1)\n",
    "\n",
    "# Renombrar la columna 'old_name' a 'new_name'\n",
    "df_items_final.rename(columns={'item_id': 'id'}, inplace=True)\n",
    "\n",
    "# Cambiamos el typo float del campo a object\n",
    "df_items_final['id'] = df_items_final['id'].astype(object)\n",
    "\n",
    "# Pasar DataFrame df_items_final a reviews_final.csv listo para los ENDPOINTS\n",
    "archivo_csv = 'items_final.csv'\n",
    "df_items_final.to_csv(archivo_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "games = pd.read_csv('games_final.csv')\n",
    "reviews = pd.read_csv('reviews_final.csv')\n",
    "items = pd.read_csv('items_final.csv')\n",
    "\n",
    "items_horas = pd.read_csv('itemsPorHorasJugadas.csv')\n",
    "Jugad_año = pd.read_csv('UserJugadoresPorYear.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MACHINE LEARNING\n",
    "MACHINE LEARNIG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SE ELIMINAN REVIEWS VACIOS Y DE OTROS IDIOMAS DIFERENTES A INGLES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SE CREA EL ARCHIVO reviews_ML.csv PARA EL ENDPOINT DE MACHINE LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el dataframe 'reviews' desde tu fuente de datos\n",
    "df = pd.read_csv('reviews_final.csv')  # Reemplaza 'reviews.csv' con tu fuente de datos\n",
    "# Asumiendo que 'id' es la columna que contiene el ID del producto y 'review' es la columna de texto\n",
    "# Si es necesario, también puedes preprocesar y limpiar los datos aquí\n",
    "\n",
    "# Reemplazar valores NaN en la columna \"review\" con cadenas vacías y luego eliminar esas filas\n",
    "df['review'].fillna('', inplace=True)\n",
    "df.drop(df[df['review'] == ''].index, inplace=True)\n",
    "\n",
    "##############\n",
    "\n",
    "# Filtra las filas con texto en inglés\n",
    "def detect_language(text):\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except LangDetectException:\n",
    "        return None\n",
    "\n",
    "# Añade una nueva columna llamada 'language' que contendrá el idioma detectado\n",
    "df['language'] = df['review'].apply(lambda x: detect_language(x) if pd.notna(x) else None)\n",
    "\n",
    "# Filtra las filas que están en inglés (código 'en' para inglés)\n",
    "df = df[df['language'] == 'en']\n",
    "\n",
    "# Elimina la columna 'language' si ya no la necesitas\n",
    "df.drop(columns=['language'], inplace=True)\n",
    "\n",
    "\n",
    "#################\n",
    "\n",
    "df_games=pd.read_csv('games_final.csv')\n",
    "\n",
    "df_games['id'] = df_games['id'].astype(str)\n",
    "df['id'] = df['id'].astype(str)\n",
    "\n",
    "# Realizar la fusión de los DataFrames usando el campo 'id' como clave de unión\n",
    "df = df.merge(df_games[['id', 'app_name']], on='id', how='inner')\n",
    "\n",
    "# Renombrar la columna 'app_name' a 'name'\n",
    "df.rename(columns={'app_name': 'name'}, inplace=True)\n",
    "\n",
    "# Ahora, el DataFrame 'df' contiene el campo 'name' que se extrajo de 'df_games'\n",
    "\n",
    "df.to_csv('reviews_ML.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
